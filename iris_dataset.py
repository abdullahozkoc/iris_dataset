# -*- coding: utf-8 -*-
"""iris_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-qqoV2Jz1XiC2FDMCejHNM0yEc265YNJ
"""

from google.colab import files
files.upload()

import pandas as pd

s = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
df = pd.read_csv(s,header=None,encoding = 'utf-8')
df.tail()

"""we extract the first feature column (sepal length) and the third feature column (petal length)
of those 100 training examples and assign them to a feature matrix, X, which we can visualize via a
two-dimensional scatterplot:
"""

import matplotlib.pyplot as plt
import numpy as np

#select setosa and versicolor
y = df.iloc[0:100,4].values
y= np.where(y=="Iris-setosa",0,1)

#extract sepal length and petal length
X = df.iloc[0:100,[0,2]].values

#plot data
plt.scatter(X[:50,0],X[:50,1],color='red',marker="o",label="Setosa")
plt.scatter(X[50:100,0],X[50:100,1],color="blue",marker="s",label="Versicolor")
plt.xlabel("Sepal length [cm]")
plt.ylabel("Petal length [cm]")
plt.legend(loc="upper left")
plt.show()

from perceptron import Perceptron

ppn = Perceptron(eta=0.1, n_iter=10)
ppn.fit(X,y)

plt.plot(range(1,len(ppn.errors_)+1),ppn.errors_, marker='o')
plt.xlabel("Epochs")
plt.ylabel("Number of updates")
plt.show()

"""Note that the number of misclassification errors and the number of updates is the same, since the
perceptron weights and bias are updated each time it misclassifies an example. After executing the
preceding code, we should see the plot of the misclassification errors versus the number of epochs, as shown above

our perceptron converged after the sixth epoch and should now be able
to classify the training examples perfectly. Letâ€™s implement a small convenience function to visualize
the decision boundaries for two-dimensional datasets
"""

from matplotlib.colors import ListedColormap

def plot_decision_regions(X,y,classifier,resolution=0.02):
  #setup marker generator and color map
  markers = ('o','s','^','v','<')
  colors=('red','blue','lightgreen','gray','cyan')
  cmap = ListedColormap(colors[:len(np.unique(y))])

  #plot the decision surface
  x1_min, x1_max= X[:,0].min()-1, X[:,0].max()+1
  x2_min, x2_max= X[:,1].min()-1, X[:,1].max()+1
  xx1,xx2=np.meshgrid(np.arange(x1_min,x1_max,resolution),np.arange(x2_min,x2_max,resolution))
  lab = classifier.predict(np.array([xx1.ravel(),xx2.ravel()]).T)
  lab = lab.reshape(xx1.shape)
  plt.contourf(xx1,xx2,lab,alpha=0.3,cmap=cmap)
  plt.xlim(xx1.min(),xx1.max())
  plt.ylim(xx2.min(),xx2.max())

  #plot class examples
  for idx, cl in enumerate(np.unique(y)):
    plt.scatter(x=X[y==cl,0],y=X[y==cl,1],alpha=0.8,c=colors[idx],marker=markers[idx],label=f"Class {cl}",edgecolor='black')

plot_decision_regions(X,y,classifier=ppn)
plt.xlabel('Sepal Length [cm]')
plt.ylabel('Petal Length [cm]')
plt.legend(loc='upper left')
plt.show()

